{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cholian/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DatasetInfo' from 'huggingface_hub.hf_api' (/Users/cholian/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/huggingface_hub/hf_api.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4g/jz_j1_cd25v2bv9plmhlqqw80000gn/T/ipykernel_52110/2254251890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load tagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flair/pos-english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/flair/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrainers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/flair/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msequence_tagger_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlanguage_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtext_classification_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpairwise_classification_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextPairClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrelation_extractor_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRelationExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStackedEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munzip_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstore_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/flair/embeddings/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Expose token embedding classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackedEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXLNetModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mTransfoXLModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2707\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__version__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2709\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/auto/__init__.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpegasus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_pegasus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPegasusForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPegasusForConditionalGeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPegasusModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprophetnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_prophetnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProphetNetForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProphetNetForConditionalGeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProphetNetModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m from ..rag.modeling_rag import (  # noqa: F401 - need to import all RagModels to be in globals() function\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mRagModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mRagSequenceForGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/rag/modeling_rag.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_rag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRagConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mretrieval_rag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRagRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/rag/retrieval_rag.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_datasets_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_from_disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_faiss_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptimizedTypedSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ArrayXD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfilesystems\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_path_from_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_remote_filesystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m from .features import (\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mFeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0m_ArrayXDExtensionType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/features/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# flake8: noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from .features import (\n\u001b[1;32m      5\u001b[0m     \u001b[0m_ArrayXD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/features/audio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_download_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/utils/streaming_download_manager.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystems\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOMPRESSION_FILESYSTEMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdownload_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m from .file_utils import (\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/filesystems/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhffilesystem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfFileSystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/datasets/filesystems/hffilesystem.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfsspec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractFileSystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_authentication_headers_for_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_hub_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DatasetInfo' from 'huggingface_hub.hf_api' (/Users/cholian/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/huggingface_hub/hf_api.py)"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/pos-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier_zero_shot_cf = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "  \n",
    "tokenizer_QA = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
    "model_QA = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mhello\u001b[0m \u001b[32mworld\u001b[0m\n",
      "\u001b[31mhello red world\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "print(colored('hello', 'red'), colored('world', 'green'))\n",
    "print(colored(\"hello red world\", 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://cryptopanic.com/api/v1/posts/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base_url = \"https://cryptopanic.com/\"\n",
    "# endpoint = \"/api/v1/posts/\"\n",
    "\n",
    "# url = urljoin(base_url,endpoint)\n",
    "# # # obtain the url\n",
    "# # url\n",
    "\n",
    "# with open('api_key.txt') as f:\n",
    "#     API_KEY = f.readlines()[0]\n",
    "    \n",
    "# params = {\n",
    "#     'auth_token':API_KEY,\n",
    "#     \"public\":\"true\", # for non-user news\n",
    "#     \"filter\":\"important\",\n",
    "# #     \"kind\":'all' # for news or media\n",
    "# }\n",
    "\n",
    "# response = requests.get(url, params = params)\n",
    "# response =response.json()\n",
    "\n",
    "# ori_data = pd.DataFrame(response['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_data.to_csv('sample_cryoto_news.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data = pd.read_csv('sample_cryoto_news.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>domain</th>\n",
       "      <th>votes</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>published_at</th>\n",
       "      <th>slug</th>\n",
       "      <th>currencies</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>u.today</td>\n",
       "      <td>{'negative': 20, 'positive': 3, 'important': 8...</td>\n",
       "      <td>{'title': 'U.Today', 'region': 'en', 'domain':...</td>\n",
       "      <td>$2.6 Billion Bug in Solana Program Library Dis...</td>\n",
       "      <td>2021-12-04T16:31:06Z</td>\n",
       "      <td>26-Billion-Bug-in-Solana-Program-Library-Discl...</td>\n",
       "      <td>[{'code': 'SOL', 'title': 'Solana', 'slug': 's...</td>\n",
       "      <td>13563922</td>\n",
       "      <td>https://cryptopanic.com/news/13563922/26-Billi...</td>\n",
       "      <td>2021-12-04T16:31:06Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>zycrypto.com</td>\n",
       "      <td>{'negative': 1, 'positive': 21, 'important': 6...</td>\n",
       "      <td>{'title': 'ZyCrypto', 'region': 'en', 'domain'...</td>\n",
       "      <td>El Salvador Increases Bitcoin Holding To Over ...</td>\n",
       "      <td>2021-12-04T15:36:28Z</td>\n",
       "      <td>El-Salvador-Increases-Bitcoin-Holding-To-Over-...</td>\n",
       "      <td>[{'code': 'BTC', 'title': 'Bitcoin', 'slug': '...</td>\n",
       "      <td>13563800</td>\n",
       "      <td>https://cryptopanic.com/news/13563800/El-Salva...</td>\n",
       "      <td>2021-12-04T15:36:28Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>u.today</td>\n",
       "      <td>{'negative': 4, 'positive': 19, 'important': 3...</td>\n",
       "      <td>{'title': 'U.Today', 'region': 'en', 'domain':...</td>\n",
       "      <td>Shiba Inu Remains Top Holding in Whale Wallets...</td>\n",
       "      <td>2021-12-04T14:48:57Z</td>\n",
       "      <td>Shiba-Inu-Remains-Top-Holding-in-Whale-Wallets...</td>\n",
       "      <td>[{'code': 'SHIB', 'title': 'Shiba Inu', 'slug'...</td>\n",
       "      <td>13563653</td>\n",
       "      <td>https://cryptopanic.com/news/13563653/Shiba-In...</td>\n",
       "      <td>2021-12-04T14:48:57Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>zycrypto.com</td>\n",
       "      <td>{'negative': 12, 'positive': 28, 'important': ...</td>\n",
       "      <td>{'title': 'ZyCrypto', 'region': 'en', 'domain'...</td>\n",
       "      <td>Three Reasons Why PlanB Is Still Bullish On Bi...</td>\n",
       "      <td>2021-12-04T13:34:04Z</td>\n",
       "      <td>Three-Reasons-Why-PlanB-Is-Still-Bullish-On-Bi...</td>\n",
       "      <td>[{'code': 'BTC', 'title': 'Bitcoin', 'slug': '...</td>\n",
       "      <td>13563492</td>\n",
       "      <td>https://cryptopanic.com/news/13563492/Three-Re...</td>\n",
       "      <td>2021-12-04T13:34:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>cryptoglobe.com</td>\n",
       "      <td>{'negative': 0, 'positive': 10, 'important': 8...</td>\n",
       "      <td>{'title': 'CryptoGlobe', 'region': 'en', 'doma...</td>\n",
       "      <td>XRP Can Now Be Used To Pay Online at Croatia’s...</td>\n",
       "      <td>2021-12-04T12:57:58Z</td>\n",
       "      <td>XRP-Can-Now-Be-Used-To-Pay-Online-at-Croatias-...</td>\n",
       "      <td>[{'code': 'BTC', 'title': 'Bitcoin', 'slug': '...</td>\n",
       "      <td>13563432</td>\n",
       "      <td>https://cryptopanic.com/news/13563432/XRP-Can-...</td>\n",
       "      <td>2021-12-04T12:57:58Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kind           domain                                              votes  \\\n",
       "0  news          u.today  {'negative': 20, 'positive': 3, 'important': 8...   \n",
       "1  news     zycrypto.com  {'negative': 1, 'positive': 21, 'important': 6...   \n",
       "2  news          u.today  {'negative': 4, 'positive': 19, 'important': 3...   \n",
       "3  news     zycrypto.com  {'negative': 12, 'positive': 28, 'important': ...   \n",
       "4  news  cryptoglobe.com  {'negative': 0, 'positive': 10, 'important': 8...   \n",
       "\n",
       "                                              source  \\\n",
       "0  {'title': 'U.Today', 'region': 'en', 'domain':...   \n",
       "1  {'title': 'ZyCrypto', 'region': 'en', 'domain'...   \n",
       "2  {'title': 'U.Today', 'region': 'en', 'domain':...   \n",
       "3  {'title': 'ZyCrypto', 'region': 'en', 'domain'...   \n",
       "4  {'title': 'CryptoGlobe', 'region': 'en', 'doma...   \n",
       "\n",
       "                                               title          published_at  \\\n",
       "0  $2.6 Billion Bug in Solana Program Library Dis...  2021-12-04T16:31:06Z   \n",
       "1  El Salvador Increases Bitcoin Holding To Over ...  2021-12-04T15:36:28Z   \n",
       "2  Shiba Inu Remains Top Holding in Whale Wallets...  2021-12-04T14:48:57Z   \n",
       "3  Three Reasons Why PlanB Is Still Bullish On Bi...  2021-12-04T13:34:04Z   \n",
       "4  XRP Can Now Be Used To Pay Online at Croatia’s...  2021-12-04T12:57:58Z   \n",
       "\n",
       "                                                slug  \\\n",
       "0  26-Billion-Bug-in-Solana-Program-Library-Discl...   \n",
       "1  El-Salvador-Increases-Bitcoin-Holding-To-Over-...   \n",
       "2  Shiba-Inu-Remains-Top-Holding-in-Whale-Wallets...   \n",
       "3  Three-Reasons-Why-PlanB-Is-Still-Bullish-On-Bi...   \n",
       "4  XRP-Can-Now-Be-Used-To-Pay-Online-at-Croatias-...   \n",
       "\n",
       "                                          currencies        id  \\\n",
       "0  [{'code': 'SOL', 'title': 'Solana', 'slug': 's...  13563922   \n",
       "1  [{'code': 'BTC', 'title': 'Bitcoin', 'slug': '...  13563800   \n",
       "2  [{'code': 'SHIB', 'title': 'Shiba Inu', 'slug'...  13563653   \n",
       "3  [{'code': 'BTC', 'title': 'Bitcoin', 'slug': '...  13563492   \n",
       "4  [{'code': 'BTC', 'title': 'Bitcoin', 'slug': '...  13563432   \n",
       "\n",
       "                                                 url            created_at  \n",
       "0  https://cryptopanic.com/news/13563922/26-Billi...  2021-12-04T16:31:06Z  \n",
       "1  https://cryptopanic.com/news/13563800/El-Salva...  2021-12-04T15:36:28Z  \n",
       "2  https://cryptopanic.com/news/13563653/Shiba-In...  2021-12-04T14:48:57Z  \n",
       "3  https://cryptopanic.com/news/13563492/Three-Re...  2021-12-04T13:34:04Z  \n",
       "4  https://cryptopanic.com/news/13563432/XRP-Can-...  2021-12-04T12:57:58Z  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ori_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4g/jz_j1_cd25v2bv9plmhlqqw80000gn/T/ipykernel_51488/1830144650.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mori_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mori_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ori_data' is not defined"
     ]
    }
   ],
   "source": [
    "title = ori_data['title']\n",
    "time = ori_data['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = Sentence('El Salvador Increases Bitcoin Holding To Over $60 Million, Tron’s Justin Sun Scoops More BTC In Solidarity')\n",
    "# # predict NER tags\n",
    "# tagger.predict(sentence)\n",
    "# for entity in sentence.get_spans('pos'):\n",
    "#     print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Program'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> Yes, it is.  It is a form of digital currency.  Do you know anything about it?</s>']\n"
     ]
    }
   ],
   "source": [
    "UTTERANCE = f\"Is {tag_text[2]} a cryptocurrency?\"\n",
    "inputs = tokenizer_QA([UTTERANCE], return_tensors='pt')\n",
    "reply_ids = model_QA.generate(**inputs)\n",
    "print(tokenizer_QA.batch_decode(reply_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTime:\u001b[0m 2021-12-04 16:31:06\n",
      "\u001b[33mNews title: \u001b[0m $2.6 Billion Bug in Solana Program Library Disclosed: Details\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Bug', 'Solana', 'Program', 'Library']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mGood\u001b[0m\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "each_time = time[i]\n",
    "t = datetime.datetime.strptime(each_time,\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "t.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "each_title = title[i]\n",
    "# make sentence\n",
    "sentence = Sentence(each_title)\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "all_tag = np.array([i.tag for i in sentence.get_spans('pos')])\n",
    "all_text = np.array([i.text for i in sentence.get_spans('pos')])\n",
    "    \n",
    "tag_text = []\n",
    "import_lb = ['NNP','NNPS',\"NN\"]\n",
    "\n",
    "for _tag,_text in zip(all_tag,all_text):\n",
    "    if _tag in import_lb:\n",
    "        tag_text.append(_text)\n",
    "\n",
    "\n",
    "self_label = ['buy','sell']\n",
    "sequence_to_classify = each_title\n",
    "candidate_labels = ['Good','Bad']\n",
    "prediction = classifier_zero_shot_cf(sequence_to_classify, candidate_labels)\n",
    "final_pred = candidate_labels[np.argmax(prediction['scores'])]\n",
    "color_GB = \"red\" if final_pred == 'Good' else \"green\"\n",
    "\n",
    "print(colored(\"Time:\",'yellow'), t)\n",
    "print(colored(\"News title: \",'yellow'),each_title)\n",
    "print(colored(\"Label: \",'yellow'),colored(tag_text,'green'))\n",
    "print(colored(\"Influence:  \",'yellow'),colored(final_pred,f'{color_GB}'))\n",
    "print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTime:\u001b[0m 2021-12-04 16:31:06\n",
      "\u001b[33mNews title: \u001b[0m $2.6 Billion Bug in Solana Program Library Disclosed: Details\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Bug', 'Solana', 'Program', 'Library']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 15:36:28\n",
      "\u001b[33mNews title: \u001b[0m El Salvador Increases Bitcoin Holding To Over $60 Million, Tron’s Justin Sun Scoops More BTC In Solidarity\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['El', 'Salvador', 'Bitcoin', 'Holding', 'Tron', 'Justin', 'Sun', 'BTC', 'Solidarity']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 14:48:57\n",
      "\u001b[33mNews title: \u001b[0m Shiba Inu Remains Top Holding in Whale Wallets After Market Drops by 25%\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Shiba', 'Inu', 'Holding', 'Whale', 'Market', '%']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 13:34:04\n",
      "\u001b[33mNews title: \u001b[0m Three Reasons Why PlanB Is Still Bullish On Bitcoin Price Hitting $100k Despite Crashing Under $50k\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['PlanB', 'Bitcoin', 'Price']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 12:57:58\n",
      "\u001b[33mNews title: \u001b[0m XRP Can Now Be Used To Pay Online at Croatia’s Largest Supermarket Chain\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['XRP', 'Online', 'Croatia', 'Supermarket', 'Chain']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 12:30:05\n",
      "\u001b[33mNews title: \u001b[0m Bitcoin, Ethereum face largest correction since 19 May; is it time to buy the dip\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Bitcoin', 'Ethereum', 'face', 'correction', 'May', 'time', 'dip']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 12:29:56\n",
      "\u001b[33mNews title: \u001b[0m Is BTC’s Drop Due to Subtle Market Manipulation?\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['BTC', 'Market', 'Manipulation']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 11:53:47\n",
      "\u001b[33mNews title: \u001b[0m Solana library bug could have seen attackers stealing $27 million an hour\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Solana', 'library', 'bug', 'hour']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 10:25:45\n",
      "\u001b[33mNews title: \u001b[0m El Salvador Buys the Dip: Purchased Another 150 BTC Worth $7.3 Million\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['El', 'Salvador', 'Dip', 'BTC']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 10:15:59\n",
      "\u001b[33mNews title: \u001b[0m Whales Are Actively Accumulating Three Altcoins – And Selling Two Others, According to Crypto Analytics Firm Santiment\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Crypto', 'Analytics', 'Firm', 'Santiment']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 09:35:12\n",
      "\u001b[33mNews title: \u001b[0m Celsius CEO projects Bitcoin to hit $140K before Q2 2022 despite sharp slump below $50k\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Celsius', 'CEO', 'Bitcoin', 'Q2', 'slump']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 09:34:46\n",
      "\u001b[33mNews title: \u001b[0m Bitcoin records a massive 16% drop as $400 billion leaves crypto market cap in a day\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Bitcoin', '%', 'drop', 'crypto', 'market', 'cap', 'day']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 08:46:05\n",
      "\u001b[33mNews title: \u001b[0m FTX releases crypto regulation proposals before US congressional hearing\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['FTX', 'crypto', 'regulation', 'US', 'hearing']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 08:04:19\n",
      "\u001b[33mNews title: \u001b[0m Epic Crash Hits Crypto Markets As Bitcoin Plummets to $43,500 in Matter of Minutes\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Crash', 'Crypto', 'Bitcoin', 'Matter']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 08:02:59\n",
      "\u001b[33mNews title: \u001b[0m Bloodbath: Bitcoin Crashed to $42K, Altcoins See Double-Digit Slumps (Market Watch)\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Bloodbath', 'Bitcoin', 'Altcoins', 'Double-Digit', 'Slumps', 'Market', 'Watch']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 07:40:05\n",
      "\u001b[33mNews title: \u001b[0m El Salvador Purchases 150 More Bitcoin As BTC Falls Below $47,000\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['El', 'Salvador', 'Bitcoin', 'BTC']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 06:56:03\n",
      "\u001b[33mNews title: \u001b[0m El Salvador stacks 150 Bitcoin after BTC price crashes below $50k\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['El', 'Salvador', 'Bitcoin', 'BTC', 'price']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 05:47:45\n",
      "\u001b[33mNews title: \u001b[0m Bitcoin tumbles below $47K wiping out October gains — Bear market begins?\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Bitcoin', 'October', 'Bear', 'market']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 03:02:23\n",
      "\u001b[33mNews title: \u001b[0m We have an incredible #CardanoCommunity!🤗\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['#', 'CardanoCommunity']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mTime:\u001b[0m 2021-12-04 02:23:11\n",
      "\u001b[33mNews title: \u001b[0m Bitcoin Prices Fell To Almost 2-Month Low—What Should Traders Expect Next?\n",
      "\u001b[33mLabel: \u001b[0m \u001b[32m['Bitcoin', 'Low']\u001b[0m\n",
      "\u001b[33mInfluence:  \u001b[0m \u001b[31mgood\u001b[0m\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(title)):\n",
    "\n",
    "    \n",
    "    each_time = time[i]\n",
    "    t = datetime.datetime.strptime(each_time,\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    t.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    \n",
    "    each_title = title[i]\n",
    "    # make sentence\n",
    "    sentence = Sentence(each_title)\n",
    "\n",
    "    # predict NER tags\n",
    "    tagger.predict(sentence)\n",
    "\n",
    "    all_tag = np.array([i.tag for i in sentence.get_spans('pos')])\n",
    "    all_text = np.array([i.text for i in sentence.get_spans('pos')])\n",
    "        \n",
    "    tag_text = []\n",
    "    import_lb = ['NNP','NNPS',\"NN\"]\n",
    "\n",
    "    for _tag,_text in zip(all_tag,all_text):\n",
    "        if _tag in import_lb:\n",
    "            tag_text.append(_text)\n",
    "\n",
    "\n",
    "\n",
    "    self_label = ['buy','sell']\n",
    "    sequence_to_classify = each_title\n",
    "    candidate_labels = ['good','bad']\n",
    "    prediction = classifier_zero_shot_cf(sequence_to_classify, candidate_labels)\n",
    "    final_pred = candidate_labels[np.argmax(prediction['scores'])]\n",
    "    color_GB = \"red\" if final_pred == 'good' else \"green\"\n",
    "\n",
    "    print(colored(\"Time:\",'yellow'), t)\n",
    "    print(colored(\"News title: \",'yellow'),each_title)\n",
    "    print(colored(\"Label: \",'yellow'),colored(tag_text,'green'))\n",
    "    print(colored(\"Influence:  \",'yellow'),colored(final_pred,f'{color_GB}'))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    # clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the beautifulsoup \n",
    "# and request libraries of python.\n",
    "import requests\n",
    "import bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = 'Solana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two strings with default google search URL\n",
    "# 'https://google.com/search?q=' and\n",
    "# our customized search keyword.\n",
    "# Concatenate them\n",
    "text= f\"is {tokens} a cryptocurrency?\"\n",
    "url = 'https://google.com/search?q=' + text\n",
    "  \n",
    "# Fetch the URL data using requests.get(url),\n",
    "# store it in a variable, request_result.\n",
    "request_result=requests.get( url )\n",
    "  \n",
    "# Creating soup from the fetched request\n",
    "soup = bs4.BeautifulSoup(request_result.text,\n",
    "                         \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cryptocurrency platform is called Solana'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_input = {\n",
    "    'question': f'is {tokens} a cryptocurrency?',\n",
    "    'context': soup.body.text\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = res['answer']\n",
    "candidate_labels = ['Yes','No','Other']\n",
    "prediction = classifier_zero_shot_cf(sequence_to_classify, candidate_labels)\n",
    "final_pred = candidate_labels[np.argmax(prediction['scores'])]\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': '$2.6 Billion Bug in Solana Program Library Disclosed: Details',\n",
       " 'labels': ['bad', 'good'],\n",
       " 'scores': [0.9373856782913208, 0.0626143366098404]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sequence_to_classify = \"one day I will see the world\"\n",
    "sequence_to_classify = title[0]\n",
    "candidate_labels = ['good','bad']\n",
    "# candidate_labels  = exchange_info['symbol']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sentence transformer env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "A man is eating food. \t A man is eating a piece of bread. \t 0.7553\n",
      "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.7369\n",
      "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6433\n",
      "A woman is playing violin. \t Someone in a gorilla costume is playing a set of drums. \t 0.2564\n",
      "A man is eating food. \t A man is riding a horse. \t 0.2474\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "528a031830962f4f937ffd0c092b889845b0f19378c058dbb596312c8f6eb8bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
